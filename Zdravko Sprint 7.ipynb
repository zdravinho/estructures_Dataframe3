{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f703fd4",
   "metadata": {},
   "source": [
    "# 1 ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654dbddd",
   "metadata": {},
   "source": [
    "En primer lugar, cargaríamos y preprocesaríamos los datos. Como no hay datos que falten, el paso de preprocesamiento sólo incluiría la normalización de las variables de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf5207ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('wineData.txt', delimiter=',', names=[\n",
    "    \"Class\",\n",
    "    \"Alcohol\",\n",
    "    \"Malic acid\",\n",
    "    \"Ash\",\n",
    "    \"Alcalinity of ash\",\n",
    "    \"Magnesium\",\n",
    "    \"Total phenols\",\n",
    "    \"Flavanoids\",\n",
    "    \"Nonflavanoid phenols\",\n",
    "    \"Proanthocyanins\",\n",
    "    \"Color intensity\",\n",
    "    \"Hue\",\n",
    "    \"OD280/OD315 of diluted wines\",\n",
    "    \"Proline\",\n",
    "])\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=['Class'])\n",
    "y = df['Class']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9f78d",
   "metadata": {},
   "source": [
    "Así implementaríamos un clasificador de árbol de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38e20e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Decision Tree Classifier:  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Entrenar un clasificador de árbol de decisión\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de pruebas\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Comprobar la precisión\n",
    "print(\"Precisión del clasificador de árbol de decisión: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace0ebb",
   "metadata": {},
   "source": [
    "Y así es como implementaríamos SVM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3aeb2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la máquina de vectores soporte:  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Entrenar una SVM\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de pruebas\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Comprobar la precisión\n",
    "print(\"Precisión de SVM: \", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7249cd1",
   "metadata": {},
   "source": [
    "# 2 ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc180b5",
   "metadata": {},
   "source": [
    "Vamos a comparar dos modelos como ejemplos: el Clasificador de Árbol de Decisión y SVM. \n",
    "\n",
    "Para la comparación, usaremos exactitud (accuracy), matriz de confusión, precisión, recall y F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a82c928f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitud del Clasificador de Árbol de Decisión:  0.9629629629629629\n",
      "Exactitud de la Máquina de Vectores de Soporte:  0.9814814814814815\n",
      "Matriz de Confusión del Clasificador de Árbol de Decisión: \n",
      "[[18  1  0]\n",
      " [ 0 21  0]\n",
      " [ 1  0 13]]\n",
      "Matriz de Confusión de la Máquina de Vectores de Soporte: \n",
      "[[19  0  0]\n",
      " [ 0 21  0]\n",
      " [ 0  1 13]]\n",
      "Informe de Clasificación del Clasificador de Árbol de Decisión: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      0.95      0.95        19\n",
      "           2       0.95      1.00      0.98        21\n",
      "           3       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.97      0.96      0.96        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n",
      "Informe de Clasificación de la Máquina de Vectores de Soporte: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        19\n",
      "           2       0.95      1.00      0.98        21\n",
      "           3       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Entrenar un Clasificador de Árbol de Decisión\n",
    "clf_tree = DecisionTreeClassifier()\n",
    "clf_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_tree = clf_tree.predict(X_test)\n",
    "\n",
    "# Entrenar una SVM\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_svm = clf_svm.predict(X_test)\n",
    "\n",
    "# Revisar la exactitud\n",
    "print(\"Exactitud del Clasificador de Árbol de Decisión: \", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"Exactitud de SVM: \", accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# Matriz de Confusión\n",
    "print(\"Matriz de Confusión del Clasificador de Árbol de Decisión: \")\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "print(\"Matriz de Confusión de SVM: \")\n",
    "print(confusion_matrix(y_test, y_pred_svm))\n",
    "\n",
    "# Precisión, Recall y F1-Score\n",
    "print(\"Informe de Clasificación del Clasificador de Árbol de Decisión: \")\n",
    "print(classification_report(y_test, y_pred_tree))\n",
    "print(\"Informe de Clasificación de la Máquina de Vectores de Soporte: \")\n",
    "print(classification_report(y_test, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072d607",
   "metadata": {},
   "source": [
    "Exactitud (Accuracy):\n",
    "\n",
    "Clasificador de Árbol de Decisión: 96.3%\n",
    "Máquina de Vectores de Soporte: 98.1%\n",
    "Ambos modelos tienen una alta exactitud, pero SVM tiene una exactitud ligeramente mayor.\n",
    "\n",
    "Matriz de Confusión:\n",
    "\n",
    "Clasificador de Árbol de Decisión: Ha clasificado erróneamente un vino de la clase 1 como clase 2 y un vino de la clase 3 como clase 1.\n",
    "Máquina de Vectores de Soporte: Ha clasificado erróneamente un vino de la clase 3 como clase 2.\n",
    "De nuevo, ambos modelos tienen un buen rendimiento, pero la Máquina de Vectores de Soporte ha cometido menos errores.\n",
    "\n",
    "Informe de Clasificación:\n",
    "\n",
    "Clasificador de Árbol de Decisión: Tiene una precisión y recall muy altas para todas las clases, con la clase 3 teniendo una recall del 93%.\n",
    "SVM: Tiene una precisión del 100% para las clases 1 y 3 y del 95% para la clase 2. El recall es del 100% para las clases 1 y 2, y del 93% para la clase 3.\n",
    "De nuevo, ambos modelos tienen una alta precisión y recall, pero SVM tiene una ligeramente mayor precisión en las clases 1 y 3 en comparación con el Clasificador de Árbol de Decisión.\n",
    "\n",
    "En resumen, ambos modelos son muy buenos para clasificar los vinos en las tres clases basándose en las características químicas dadas. Sin embargo, SVM ha demostrado un rendimiento ligeramente mejor en esta tarea específica. Eso sí, hay que tener en cuenta que estos resultados pueden variar si cambiamos la semilla aleatoria o si utilizamos diferentes conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af16ba19",
   "metadata": {},
   "source": [
    "Precisión - nos indica qué proporción de positivos predichos es verdaderamente positiva.\n",
    "Recall - nos indica qué proporción de positivos reales se clasifica correctamente.\n",
    "F1-Score - la media armónica de la precisión y el recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef206d3",
   "metadata": {},
   "source": [
    "# 3 ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc4dd00",
   "metadata": {},
   "source": [
    "Aqui vamos usar RandomizedSearchCV. RandomizedSearchCV es una técnica de ajuste de hiperparámetros en aprendizaje automático. Los hiperparámetros son las \"configuraciones\" de un algoritmo de aprendizaje automático que se deben definir antes de entrenar el modelo. Diferentes configuraciones pueden producir diferentes resultados, y el objetivo es encontrar la configuración que produzca los mejores resultados en tus datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de9a08e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para el Clasificador de Árbol de Decisión:  {'min_samples_split': 11, 'min_samples_leaf': 6, 'max_depth': 14}\n",
      "Mejores parámetros para SVM:  {'kernel': 'linear', 'gamma': 0.001, 'C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "\n",
    "# Parámetros para el Clasificador de Árbol de Decisión\n",
    "params_tree = {'max_depth': [None] + list(np.arange(2, 20)),\n",
    "               'min_samples_split': np.arange(2, 20),\n",
    "               'min_samples_leaf': np.arange(1, 20)}\n",
    "\n",
    "random_search_tree = RandomizedSearchCV(DecisionTreeClassifier(), params_tree, n_iter=100, cv=5)\n",
    "random_search_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros para el Clasificador de Árbol de Decisión: \", random_search_tree.best_params_)\n",
    "\n",
    "# Parámetros para SVM\n",
    "params_svm = {'C': np.logspace(-3, 2, 6),\n",
    "              'gamma': np.logspace(-3, 2, 6),\n",
    "              'kernel': ['linear', 'rbf']}\n",
    "\n",
    "random_search_svm = RandomizedSearchCV(svm.SVC(), params_svm, n_iter=100, cv=5)\n",
    "random_search_svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros para SVM: \", random_search_svm.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc79d6",
   "metadata": {},
   "source": [
    "Para el Clasificador de Árbol de Decisión:\n",
    "\n",
    "'min_samples_split': 11, significa que el número mínimo de muestras requeridas para dividir un nodo interno es 11. En otras palabras, un nodo se dividirá si contiene al menos 11 muestras.\n",
    "'min_samples_leaf': 6, significa que el número mínimo de muestras requeridas para ser un nodo hoja es 6. Un nodo dividido generará al menos un nodo hijo que contenga al menos 6 muestras.\n",
    "'max_depth': 14, indica la profundidad máxima del árbol. Los árboles más profundos pueden modelar relaciones más complejas al agregar más divisiones en el árbol, pero también pueden causar sobreajuste.\n",
    "\n",
    "Para SVM:\n",
    "\n",
    "'kernel': 'linear', significa que se está utilizando una función de kernel lineal para transformar los datos. Las funciones de kernel se utilizan para transformar los datos a una dimensión superior donde se pueden separar con un hiperplano.\n",
    "'gamma': 0.001, es el coeficiente para las funciones de kernel 'rbf', 'poly' y 'sigmoid'. Dado que estás utilizando un kernel 'linear', este parámetro no es relevante en este contexto.\n",
    "'C': 1.0, es el parámetro de penalización del término de error. Un valor más pequeño de C crea un margen más amplio, lo que puede dar lugar a más errores de clasificación. Un valor más grande de C crea un margen más pequeño, que puede hacer que el modelo se ajuste demasiado a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ef5de5",
   "metadata": {},
   "source": [
    "# 4 ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1c9ae9",
   "metadata": {},
   "source": [
    "Para comparar el rendimiento de los modelos utilizando los enfoques de entrenamiento/prueba y validación cruzada, necesitaríamos ejecutar ambos procesos y luego comparar los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b520284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación promedio de validación cruzada para Clasificador de Árbol de Decisión:  0.8771428571428572\n",
      "Puntuación promedio de validación cruzada para SVM:  0.961111111111111\n",
      "Puntuación de entrenamiento/prueba para Clasificador de Árbol de Decisión:  0.9444444444444444\n",
      "Puntuación de entrenamiento/prueba para SVM:  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "# Clasificador de Arbol de Decisión con los mejores parámetros\n",
    "dtc = DecisionTreeClassifier(min_samples_split=11, min_samples_leaf=6, max_depth=14)\n",
    "dtc.fit(X_train, y_train)\n",
    "\n",
    "# SVM con los mejores parámetros\n",
    "svm = SVC(kernel='linear', gamma=0.001, C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Puntuaciones de validación cruzada\n",
    "dtc_cv_scores = cross_val_score(dtc, X, y, cv=5)\n",
    "svm_cv_scores = cross_val_score(svm, X, y, cv=5)\n",
    "\n",
    "# Imprimir puntuaciones de validación cruzada promedio\n",
    "print('Puntuación promedio de validación cruzada para Clasificador de Árbol de Decisión: ', dtc_cv_scores.mean())\n",
    "print('Puntuación promedio de validación cruzada para SVM: ', svm_cv_scores.mean())\n",
    "\n",
    "# Puntuaciones de entrenamiento/prueba\n",
    "dtc_test_score = dtc.score(X_test, y_test)\n",
    "svm_test_score = svm.score(X_test, y_test)\n",
    "\n",
    "# Imprimir puntuaciones de entrenamiento/prueba\n",
    "print('Puntuación de entrenamiento/prueba para Clasificador de Árbol de Decisión: ', dtc_test_score)\n",
    "print('Puntuación de entrenamiento/prueba para SVM: ', svm_test_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b079c1fe",
   "metadata": {},
   "source": [
    "Puntuación promedio de validación cruzada para el Clasificador de Árbol de Decisión: Este valor (0.877) indica que, en promedio, el Clasificador de Árbol de Decisión es capaz de clasificar correctamente el 87.7% de los casos en diferentes particiones de los datos durante el proceso de validación cruzada. La validación cruzada es una técnica utilizada para evaluar la capacidad del modelo para generalizar a datos no vistos.\n",
    "\n",
    "Puntuación promedio de validación cruzada para SVM: Este valor (0.961) indica que, en promedio, el modelo SVM es capaz de clasificar correctamente el 96.1% de los casos en diferentes particiones de los datos durante el proceso de validación cruzada. Esto sugiere que el modelo SVM tiene un rendimiento superior al Clasificador de Árbol de Decisión en términos de validación cruzada.\n",
    "\n",
    "Puntuación de entrenamiento/prueba para el Clasificador de Árbol de Decisión: Este valor (0.944) indica que el Clasificador de Árbol de Decisión es capaz de clasificar correctamente el 94.4% de los casos en el conjunto de datos de prueba.\n",
    "\n",
    "Puntuación de entrenamiento/prueba para SVM: Este valor (0.981) indica que el modelo SVM es capaz de clasificar correctamente el 98.1% de los casos en el conjunto de datos de prueba. Esto sugiere que el modelo SVM también tiene un rendimiento superior al Clasificador de Árbol de Decisión en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcbcf94",
   "metadata": {},
   "source": [
    "# 5 ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20deb8d",
   "metadata": {},
   "source": [
    "Con esta tecnica \"Selección de características\" podríamos aplicar algún método de selección de características para reducir la dimensionalidad y eliminar las características menos informativas. No todas las características son igualmente útiles para la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1526d391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación con características seleccionadas:  0.9814814814814815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Crear el RFE object y clasificar en base a la potencia de los predictores\n",
    "selector = RFE(svm, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# Aplicar la selección de características al conjunto de entrenamiento y prueba\n",
    "X_train_rfe = selector.transform(X_train)\n",
    "X_test_rfe = selector.transform(X_test)\n",
    "\n",
    "# Volver a entrenar el modelo con las características seleccionadas\n",
    "svm.fit(X_train_rfe, y_train)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print('Puntuación con características seleccionadas: ', svm.score(X_test_rfe, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efaf028",
   "metadata": {},
   "source": [
    "La puntuación que se obtiene después de realizar la selección de características es una medida de la precisión del modelo en la clasificación de los datos de prueba. En este caso, la puntuación es de 0.981, lo que indica que el modelo fue capaz de predecir correctamente el 98.1% de las instancias en el conjunto de datos de prueba\n",
    "\n",
    "El hecho de que esta puntuación sea igual a la puntuación obtenida antes de la selección de características sugiere que las características que eliminamos no eran esenciales para la predicción. Asi podemos reducir la complejidad del modelo (al usar menos características) sin sacrificar el rendimiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
